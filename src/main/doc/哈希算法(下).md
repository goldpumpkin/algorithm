### 负载均衡

1. 负载均衡的策略有多种：随机、加权随机、轮询、哈希---实现会话粘滞(Seesion Sticky)等

2. 会话粘滞的实现方式

   + 普通：维护客户端ip和服务器的映射列表

     局限性很大，客户端ip和服务器的变动，都要对映射表作出改动

   + 哈希算法实现

     + 对服务器编号 0~n-1

     + 对客户端ip进行哈希计算

     + 哈希值对服务器数量n做取模运算

       这里有个小小的优化，HashMap 的 index 的计算是通过「与」运算，替代取模运算，这样运算效率比较高，注意能够替代是因为，HashMap 中哈希表的大小为 2的n次方才行

### 数据分片

1. 例子一：统计“搜索关键词”的次数

   条件：日志1T，无法放到一台机器的内存中，并且一台机器处理时间会很长

   解决：准备n台机器，将关键词通过哈希算法计算，再进行对n取模，那么一台机器会处理某些关键词的统计任务，维护本地散列表，最终将所有机器的统计结果合并起来

2. 例子二：快速判断图片是否在图库中

   条件：1亿张图片

   思路类似例子一

3. 总结

   对于海量数据的处理，我们可以采用多机分布式处理，借助分片的思路，可突破单机内存、CPU资源的限制

   对数据分片的思想是MapReduce 的基本设计思想

### 分布式存储

对数据的分布式存储，比如：数据库的分表、Redis 分布式集群

1. 方案一：类似之前的方案，对数据做哈希运算，对哈希值取模，分配到相应的机器上

   问题：数据量的增长，机器的存储不够，那机器的数量的增加，那么之前旧数据的哈希值取模的会变，将带来数据的迁移的工作，如果一个机器的数据量很大，那么迁移的数据也将很大。

   如果是缓存，那么此时会造成大量数据失效，随之带来雪崩效应，压垮数据库

   此方案的小优化：扩容每次扩为原来的2倍，这样每次迁移数据大约在百分之50

2. 方案二：使用一致性哈希算法

   思想：将哈希值 [0, 2^32] 构成一个环，每个节点分配一个 token， 在数据进行查询时，计算key的哈希值，顺时针找到第一个大于等于该哈希值的token节点。

   优势：节点的删除和新增，只会影响到相邻节点数据的迁移变动

   问题：

   + 不适合节点数量较少的情况：节点数量的变动会影响大范围哈希环中的数据
   + 普通一致性哈希分区在增减节点时候，需要增加一倍或者减去一半节点，才能保证数据和负载的均衡
   + 加减节点会造成哈希环中的部分数据无法命中，因此常用于缓存场景

   优化点：

   1. 节点数量少，可能导致哈希环倾斜，采用虚拟节点，保证数据的均匀分配

   2. 采用虚拟槽分区 --- Redis 集群使用的方案

      redis并没有使用一致性hash，而是引入了槽的概念，槽数远远大于节点数，每个节点均匀的负责一部分槽，节点的增加和删除，会迁移每个节点的一部分槽和数据。这样做的好处，使得数据的负载更加均衡，对扩容和缩容的节点数并没有倍数要求即可实现负载更加均衡

   **总结**

   一致性哈希即是对哈希值[0, max]和节点构建哈希环，对数据进行节点计算直接找到对应节点进行存储，另一种**非一致性方案**是在哈希值和节点之前加入一层，槽的概念，解耦 数据、节点，通过数据计算哈希值找到对应的槽点，根据槽点和节点的映射关系，找到节点进行存储。

### 问题

1. 哈希算法的其他应用场景
   + 网络协议的 CRC 校验
   + Git Command id
   + Docker 镜像的id 是由镜像内容生成的哈希值作为唯一标识
   + Redis 的集群方案(采用虚拟槽而非一致性哈希)
   + mysql数据库中间件mycal进行分库和分表用的是hash算法

